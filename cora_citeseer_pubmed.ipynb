{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install dgl torch torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 982
        },
        "id": "rjtBRwDhxgq5",
        "outputId": "0c461faf-736e-4af1-8ebc-7a1e98f387c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dgl\n",
            "  Using cached dgl-2.1.0-cp311-cp311-manylinux1_x86_64.whl.metadata (553 bytes)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.0.1)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (1.24.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (1.14.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.11/dist-packages (from dgl) (3.4.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from dgl) (4.67.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from dgl) (0.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch) (18.1.8)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached dgl-2.1.0-cp311-cp311-manylinux1_x86_64.whl (8.6 MB)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-2.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dgl"
                ]
              },
              "id": "8b55b8b6839746e4a0da0f96c00aa344"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCTBTyUqrTsz",
        "outputId": "a7fcd8dd-f11a-4898-bdbf-61b671d16264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchdata 0.6.1\n",
            "Uninstalling torchdata-0.6.1:\n",
            "  Successfully uninstalled torchdata-0.6.1\n",
            "Found existing installation: torch-geometric 2.6.1\n",
            "Uninstalling torch-geometric-2.6.1:\n",
            "  Successfully uninstalled torch-geometric-2.6.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch) (18.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting torchdata==0.6.1\n",
            "  Using cached torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.1) (2.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.1) (2.32.3)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.1) (2.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (4.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchdata==0.6.1) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchdata==0.6.1) (75.2.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchdata==0.6.1) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->torchdata==0.6.1) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->torchdata==0.6.1) (18.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.6.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.6.1) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.6.1) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1->torchdata==0.6.1) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1->torchdata==0.6.1) (1.3.0)\n",
            "Using cached torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "Installing collected packages: torchdata\n",
            "Successfully installed torchdata-0.6.1\n",
            "Collecting torch-geometric\n",
            "  Using cached torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Using cached torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y torchdata\n",
        "#!pip uninstall -y dgl\n",
        "!pip uninstall -y torch-geometric\n",
        "\n",
        "# Reinstall with correct versions\n",
        "!pip install torch\n",
        "!pip install torchdata==0.6.1\n",
        "#!pip install dgl==2.1.0\n",
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy\n",
        "!pip install numpy==1.24.3  # Stable version for compatibility with PyTorch and DGL\n",
        "!pip uninstall -y dgl\n",
        "#!pip install dgl==2.1.0\n",
        "!pip install dgl-cu117 -f https://data.dgl.ai/wheels/repo.html\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv pyg-lib  \\\n",
        "  -f https://data.pyg.org/whl/torch-2.0.1+cu117.html\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "id": "9wqQpD-ztsOe",
        "outputId": "7206bf0e-c98e-4072-bc37-b208e6786c47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.24.3\n",
            "Uninstalling numpy-1.24.3:\n",
            "  Successfully uninstalled numpy-1.24.3\n",
            "Collecting numpy==1.24.3\n",
            "  Using cached numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Using cached numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pymc 5.21.2 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.0.1 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\n",
            "albucore 0.0.23 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "blosc2 3.2.1 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 2.0.5 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "d2be2e0ec0634355bffa0902cf86cbcb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: dgl 2.1.0\n",
            "Uninstalling dgl-2.1.0:\n",
            "  Successfully uninstalled dgl-2.1.0\n",
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Requirement already satisfied: dgl-cu117 in /usr/local/lib/python3.11/dist-packages (0.9.1.post1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from dgl-cu117) (1.24.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from dgl-cu117) (1.14.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.11/dist-packages (from dgl-cu117) (3.4.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from dgl-cu117) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from dgl-cu117) (4.67.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from dgl-cu117) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl-cu117) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl-cu117) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl-cu117) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->dgl-cu117) (2025.1.31)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.1+cu117.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt20cu117)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt20cu117)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.11/dist-packages (1.6.3+pt20cu117)\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.11/dist-packages (1.2.2+pt20cu117)\n",
            "Requirement already satisfied: pyg-lib in /usr/local/lib/python3.11/dist-packages (0.4.0+pt20cu117)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.14.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GCNConv\n",
        "import dgl\n",
        "import numpy as np\n",
        "import time\n"
      ],
      "metadata": {
        "id": "G1tu7GrWxAqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(torch.__version__)\n",
        "print(torch.version.cuda)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaAlYSqsxOJv",
        "outputId": "8a54699d-a38f-4287-c3be-bd9570abd065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu117\n",
            "11.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyg_lib  # should import without error\n"
      ],
      "metadata": {
        "id": "oPWCEEf2w7pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ommnG3NC9PD",
        "outputId": "9ec73746-ce13-4778-e3b4-95cf6f8a9626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Cora**"
      ],
      "metadata": {
        "id": "1npxOMitjIqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Cora dataset\n",
        "cora_dataset = Planetoid(root='data/Cora', name='Cora')\n",
        "cora_data = cora_dataset[0].to(device) # Assume only one graph in the dataset"
      ],
      "metadata": {
        "id": "GsIFlWx-0ShX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ced8d3c5-cb36-433c-9364-119aa8bc1b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device_list = [torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
        "print(f\"Using {len(device_list)} GPUs:\", device_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd6Nz8Qsu4qv",
        "outputId": "33553a77-72cf-4c15-bb18-8e6ac0ff7cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 1 GPUs: [device(type='cuda', index=0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.loader import NeighborLoader\n"
      ],
      "metadata": {
        "id": "CVpL57KQveGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**GCN implementation**"
      ],
      "metadata": {
        "id": "FGqODm9Drxkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define GCN model\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, dropout_rate=0.5):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_dim)  # Added batch normalization\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = torch.dropout(x, p=self.dropout_rate, train=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2uLzhUk70X1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**GAT implementation**"
      ],
      "metadata": {
        "id": "2gSso9YMr_bP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GATConv, SAGEConv\n",
        "class GAT(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, heads=8, dropout=0.6):\n",
        "        super(GAT, self).__init__()\n",
        "        self.gat1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=dropout)\n",
        "        self.gat2 = GATConv(hidden_dim * heads, output_dim, heads=1, concat=False, dropout=dropout)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.gat1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = torch.dropout(x, p=0.6, train=self.training)\n",
        "        x = self.gat2(x, edge_index)\n",
        "        return x"
      ],
      "metadata": {
        "id": "AXFivdtyYsIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**SAGE implementation**"
      ],
      "metadata": {
        "id": "meQagTo9sClg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.6):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
        "        self.conv2 = SAGEConv(hidden_dim, output_dim)\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = torch.relu(x)\n",
        "        x = torch.dropout(x, self.dropout, train=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Pi1vaKRbYxD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert PyG graph to DGL graph\n",
        "def pyg_to_dgl(data):\n",
        "    src, dst = data.edge_index.cpu()\n",
        "    dgl_graph = dgl.graph((src, dst))  # Create DGL graph\n",
        "    dgl_graph.ndata['feat'] = data.x.cpu()   # Add node features\n",
        "    return dgl_graph\n"
      ],
      "metadata": {
        "id": "hYiVjBad0aHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adaptive graph partitioning based on partition size and node degree\n",
        "def adaptive_partitioning(dgl_graph, num_partitions=4, imbalance_threshold=1.5):\n",
        "    # Ensure graph is on CPU for METIS partitioning\n",
        "    dgl_graph_cpu = dgl_graph.to('cpu')\n",
        "\n",
        "    # Partition the graph using METIS\n",
        "    partition = dgl.metis_partition_assignment(dgl_graph_cpu, num_partitions)\n",
        "\n",
        "    # Check for imbalance between partition sizes\n",
        "    partition_sizes = torch.bincount(partition)\n",
        "    imbalance_ratio = partition_sizes.max().item() / partition_sizes.min().item()\n",
        "\n",
        "    # Trigger re-partitioning if imbalance exceeds the threshold\n",
        "    if imbalance_ratio > imbalance_threshold:\n",
        "        print(f\"Re-partitioning triggered due to imbalance: {partition_sizes.tolist()} with ratio {imbalance_ratio:.2f}\")\n",
        "        partition = dgl.metis_partition_assignment(dgl_graph_cpu, num_partitions)\n",
        "\n",
        "    # Attach partition info and move back to GPU\n",
        "    dgl_graph_cpu.ndata['part'] = partition\n",
        "    dgl_graph_gpu = dgl_graph_cpu.to(device)\n",
        "    return dgl_graph_gpu"
      ],
      "metadata": {
        "id": "3Yqm-FguO-u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function with fully adaptive dynamic partitioning\n",
        "def train_gnn(model, data, optimizer, criterion, epochs, num_partitions=4, partition_interval=5, imbalance_threshold=1.5):\n",
        "    model.train()\n",
        "    dgl_graph = pyg_to_dgl(data)\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Initial partitioning\n",
        "    partition = adaptive_partitioning(dgl_graph, num_partitions, imbalance_threshold)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Perform dynamic partitioning at intervals or when imbalance is detected\n",
        "        if epoch % partition_interval == 0:\n",
        "            partition = adaptive_partitioning(dgl_graph, num_partitions, imbalance_threshold)\n",
        "\n",
        "        # Train on each partition\n",
        "        for part_id in range(num_partitions):\n",
        "            # Get nodes in the current partition\n",
        "            node_mask = (partition.ndata['part'] == part_id)\n",
        "            if node_mask.sum() == 0:\n",
        "                continue\n",
        "            subgraph = dgl.node_subgraph(partition, node_mask)\n",
        "\n",
        "            # Get features and edge index for the subgraph\n",
        "            x = subgraph.ndata['feat']\n",
        "            edge_index = torch.stack(subgraph.edges()).to(device)\n",
        "\n",
        "            # Get the train mask for the current partition\n",
        "            subgraph_train_mask = data.train_mask[node_mask]\n",
        "\n",
        "            # Forward pass\n",
        "            optimizer.zero_grad()\n",
        "            output = model(x, edge_index)\n",
        "            loss = criterion(output[subgraph_train_mask], data.y[node_mask.cpu()][subgraph_train_mask])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    end_time = time.time()\n",
        "    return end_time - start_time\n",
        "\n"
      ],
      "metadata": {
        "id": "rSZBhOts0hhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate function\n",
        "def evaluate_model(model, data, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        data_x = data.x\n",
        "        data_edge_index = data.edge_index\n",
        "        data_y = data.y\n",
        "\n",
        "        start_time = time.time()\n",
        "        output = model(data_x, data_edge_index)\n",
        "        predictions = output[mask].argmax(dim=1)\n",
        "        correct = (predictions == data_y[mask]).sum().item()\n",
        "        accuracy = correct / mask.sum().item()\n",
        "        end_time = time.time()\n",
        "\n",
        "    inference_time = end_time - start_time\n",
        "    return accuracy, inference_time\n"
      ],
      "metadata": {
        "id": "zvMvsG7G0kcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_partition_loaders(data, num_partitions, batch_size):\n",
        "    loaders = []\n",
        "    for p in range(num_partitions):\n",
        "        mask = (data.part == p) & data.train_mask\n",
        "        if mask.sum() == 0:\n",
        "            continue\n",
        "        loader = NeighborLoader(\n",
        "            data,\n",
        "            num_neighbors=[10, 10],\n",
        "            input_nodes=mask.nonzero(as_tuple=True)[0],\n",
        "            batch_size=batch_size,\n",
        "            shuffle=True\n",
        "        )\n",
        "        loaders.append(loader)\n",
        "    return loaders\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VLxvQObrVkV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_minibatch(model, data, train_loaders, optimizer, criterion, epochs, partition_interval):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        if epoch % partition_interval == 0 and epoch != 0:\n",
        "            # Re-partition the graph\n",
        "            print(f\"\\n[Epoch {epoch}] Re-partitioning graph...\")\n",
        "            dgl_graph = pyg_to_dgl(data)\n",
        "            dgl_graph = adaptive_partitioning(dgl_graph, num_partitions=num_partitions, imbalance_threshold=imbalance_threshold)\n",
        "            data.part = dgl_graph.ndata['part'].to(data.x.device)\n",
        "            train_loaders = create_partition_loaders(data, num_partitions, batch_size=64)\n",
        "\n",
        "        for loader in train_loaders:\n",
        "            for batch in loader:\n",
        "                batch = batch.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                out = model(batch.x, batch.edge_index)\n",
        "                loss = criterion(out[batch.train_mask], batch.y[batch.train_mask])\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch}, Loss: {total_loss:.4f}, Time: {time.time() - start_time:.2f}s\")\n"
      ],
      "metadata": {
        "id": "AbjpkPhPvyZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(data.x, data.edge_index)\n",
        "        pred = out[mask].argmax(dim=1)\n",
        "        acc = (pred == data.y[mask]).sum().item() / mask.sum().item()\n",
        "        return acc\n"
      ],
      "metadata": {
        "id": "2OnzMeenwKCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_sparse"
      ],
      "metadata": {
        "id": "blGxCEAdxwf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"pyg-lib version:\", pyg_lib.__version__)\n",
        "print(\"torch-sparse version:\", torch_sparse.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdSDc7NRxy1T",
        "outputId": "8ebda5ca-dd0d-4a9b-88d9-80b5987f4138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pyg-lib version: 0.4.0+pt20cu117\n",
            "torch-sparse version: 0.6.18+pt20cu117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GCN model - CORA**"
      ],
      "metadata": {
        "id": "bzNk1xIPji4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = cora_data.num_features\n",
        "hidden_dim = 64\n",
        "output_dim = int(cora_data.y.max() - cora_data.y.min() + 1)\n",
        "# learning_rate = 0.1\n",
        "epochs = 50\n",
        "num_partitions = 128  # Number of partitions for adaptive partitioning\n",
        "partition_interval = 5  # Re-partition every 5 epochs\n",
        "imbalance_threshold = 1.5  # Max allowed partition imbalance ratio\n",
        "\n",
        "# Convert PyG to DGL and apply adaptive partitioning\n",
        "dgl_graph = pyg_to_dgl(cora_data)\n",
        "dgl_graph = adaptive_partitioning(dgl_graph, num_partitions=num_partitions, imbalance_threshold=imbalance_threshold)\n",
        "\n",
        "# Copy the partition info back to PyG object for compatibility\n",
        "partition_tensor = dgl_graph.ndata['part'].to(cora_data.x.device)\n",
        "cora_data.part = partition_tensor\n",
        "\n",
        "train_loaders = create_partition_loaders(cora_data, num_partitions, batch_size=64)\n",
        "\n",
        "gcn_model = GCN(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim).to(device)\n",
        "optimizer = torch.optim.Adam(gcn_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "train_minibatch(gcn_model, cora_data, train_loaders, optimizer, criterion, epochs=epochs, partition_interval=partition_interval)\n",
        "test_acc = evaluate(gcn_model, cora_data, cora_data.test_mask)\n",
        "\n",
        "print(\"Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExdS4j-0ja83",
        "outputId": "53ad1cb4-fb77-489b-8c95-75abe453d2ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.563 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.563 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.563 GB\n",
            "Epoch 0, Loss: 149.2296, Time: 0.30s\n",
            "Epoch 1, Loss: 104.3701, Time: 0.30s\n",
            "Epoch 2, Loss: 60.7357, Time: 0.31s\n",
            "Epoch 3, Loss: 31.8678, Time: 0.30s\n",
            "Epoch 4, Loss: 18.1165, Time: 0.30s\n",
            "\n",
            "[Epoch 5] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.563 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.563 GB\n",
            "Metis partitioning: 0.018 seconds, peak memory: 13.563 GB\n",
            "Epoch 5, Loss: 15.6307, Time: 0.45s\n",
            "Epoch 6, Loss: 8.6242, Time: 0.32s\n",
            "Epoch 7, Loss: 7.0666, Time: 0.32s\n",
            "Epoch 8, Loss: 4.1852, Time: 0.33s\n",
            "Epoch 9, Loss: 3.0751, Time: 0.33s\n",
            "\n",
            "[Epoch 10] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.563 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.563 GB\n",
            "Metis partitioning: 0.018 seconds, peak memory: 13.563 GB\n",
            "Epoch 10, Loss: 3.2237, Time: 0.43s\n",
            "Epoch 11, Loss: 2.1459, Time: 0.33s\n",
            "Epoch 12, Loss: 2.1033, Time: 0.33s\n",
            "Epoch 13, Loss: 2.1354, Time: 0.33s\n",
            "Epoch 14, Loss: 1.8255, Time: 0.34s\n",
            "\n",
            "[Epoch 15] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.563 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.563 GB\n",
            "Metis partitioning: 0.018 seconds, peak memory: 13.563 GB\n",
            "Epoch 15, Loss: 1.7849, Time: 0.40s\n",
            "Epoch 16, Loss: 1.2814, Time: 0.32s\n",
            "Epoch 17, Loss: 1.2478, Time: 0.36s\n",
            "Epoch 18, Loss: 2.5097, Time: 0.38s\n",
            "Epoch 19, Loss: 1.0764, Time: 0.37s\n",
            "\n",
            "[Epoch 20] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.563 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.563 GB\n",
            "Metis partitioning: 0.025 seconds, peak memory: 13.563 GB\n",
            "Epoch 20, Loss: 0.8758, Time: 0.53s\n",
            "Epoch 21, Loss: 0.7620, Time: 0.45s\n",
            "Epoch 22, Loss: 0.6925, Time: 0.43s\n",
            "Epoch 23, Loss: 0.4454, Time: 0.34s\n",
            "Epoch 24, Loss: 0.4124, Time: 0.34s\n",
            "\n",
            "[Epoch 25] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.563 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.563 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.563 GB\n",
            "Epoch 25, Loss: 0.4467, Time: 0.41s\n",
            "Epoch 26, Loss: 0.4597, Time: 0.31s\n",
            "Epoch 27, Loss: 0.3719, Time: 0.31s\n",
            "Epoch 28, Loss: 0.3811, Time: 0.31s\n",
            "Epoch 29, Loss: 0.3584, Time: 0.31s\n",
            "\n",
            "[Epoch 30] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.563 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.563 GB\n",
            "Metis partitioning: 0.018 seconds, peak memory: 13.563 GB\n",
            "Epoch 30, Loss: 0.2335, Time: 0.42s\n",
            "Epoch 31, Loss: 0.5253, Time: 0.34s\n",
            "Epoch 32, Loss: 0.3187, Time: 0.35s\n",
            "Epoch 33, Loss: 0.2693, Time: 0.35s\n",
            "Epoch 34, Loss: 0.1918, Time: 0.35s\n",
            "\n",
            "[Epoch 35] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.563 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.563 GB\n",
            "Metis partitioning: 0.019 seconds, peak memory: 13.563 GB\n",
            "Epoch 35, Loss: 0.2366, Time: 0.43s\n",
            "Epoch 36, Loss: 0.1704, Time: 0.34s\n",
            "Epoch 37, Loss: 0.1708, Time: 0.33s\n",
            "Epoch 38, Loss: 0.1261, Time: 0.34s\n",
            "Epoch 39, Loss: 0.1900, Time: 0.35s\n",
            "\n",
            "[Epoch 40] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.001 seconds, peak memory: 13.563 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.563 GB\n",
            "Metis partitioning: 0.023 seconds, peak memory: 13.563 GB\n",
            "Epoch 40, Loss: 0.1268, Time: 0.44s\n",
            "Epoch 41, Loss: 0.1838, Time: 0.34s\n",
            "Epoch 42, Loss: 0.1518, Time: 0.35s\n",
            "Epoch 43, Loss: 0.1489, Time: 0.35s\n",
            "Epoch 44, Loss: 0.1699, Time: 0.36s\n",
            "\n",
            "[Epoch 45] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.563 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.563 GB\n",
            "Metis partitioning: 0.020 seconds, peak memory: 13.563 GB\n",
            "Epoch 45, Loss: 0.1584, Time: 0.43s\n",
            "Epoch 46, Loss: 0.0918, Time: 0.33s\n",
            "Epoch 47, Loss: 0.1018, Time: 0.33s\n",
            "Epoch 48, Loss: 0.0631, Time: 0.33s\n",
            "Epoch 49, Loss: 0.0930, Time: 0.34s\n",
            "Test Accuracy: 0.805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GAT model - CORA**"
      ],
      "metadata": {
        "id": "669PlK8kjnYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = cora_data.num_features\n",
        "hidden_dim = 64\n",
        "output_dim = int(cora_data.y.max() - cora_data.y.min() + 1)\n",
        "# learning_rate = 0.1\n",
        "epochs = 50\n",
        "num_partitions = 128  # Number of partitions for adaptive partitioning\n",
        "partition_interval = 5  # Re-partition every 5 epochs\n",
        "imbalance_threshold = 1.5  # Max allowed partition imbalance ratio\n",
        "\n",
        "# Convert PyG to DGL and apply adaptive partitioning\n",
        "dgl_graph = pyg_to_dgl(cora_data)\n",
        "dgl_graph = adaptive_partitioning(dgl_graph, num_partitions=num_partitions, imbalance_threshold=imbalance_threshold)\n",
        "\n",
        "# Copy the partition info back to PyG object for compatibility\n",
        "partition_tensor = dgl_graph.ndata['part'].to(cora_data.x.device)\n",
        "cora_data.part = partition_tensor\n",
        "\n",
        "train_loaders = create_partition_loaders(cora_data, num_partitions, batch_size=64)\n",
        "\n",
        "gat_model = GAT(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim).to(device)\n",
        "optimizer = torch.optim.Adam(gat_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "train_minibatch(gat_model, cora_data, train_loaders, optimizer, criterion, epochs=epochs, partition_interval=partition_interval)\n",
        "test_acc = evaluate(gat_model, cora_data, cora_data.test_mask)\n",
        "\n",
        "print(\"Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjRutYPQwNhE",
        "outputId": "1cab249e-cc72-4c37-aa37-e536e7cfbe93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.460 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.460 GB\n",
            "Metis partitioning: 0.018 seconds, peak memory: 13.460 GB\n",
            "Epoch 0, Loss: 171.7317, Time: 0.50s\n",
            "Epoch 1, Loss: 128.9949, Time: 0.49s\n",
            "Epoch 2, Loss: 107.8815, Time: 0.50s\n",
            "Epoch 3, Loss: 87.4326, Time: 0.48s\n",
            "Epoch 4, Loss: 71.7495, Time: 0.48s\n",
            "\n",
            "[Epoch 5] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.461 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.461 GB\n",
            "Metis partitioning: 0.019 seconds, peak memory: 13.461 GB\n",
            "Epoch 5, Loss: 59.3898, Time: 0.56s\n",
            "Epoch 6, Loss: 49.5070, Time: 0.46s\n",
            "Epoch 7, Loss: 52.5654, Time: 0.47s\n",
            "Epoch 8, Loss: 44.7127, Time: 0.46s\n",
            "Epoch 9, Loss: 52.6056, Time: 0.58s\n",
            "\n",
            "[Epoch 10] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.001 seconds, peak memory: 13.461 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.461 GB\n",
            "Metis partitioning: 0.023 seconds, peak memory: 13.461 GB\n",
            "Epoch 10, Loss: 53.4122, Time: 0.68s\n",
            "Epoch 11, Loss: 57.2532, Time: 0.63s\n",
            "Epoch 12, Loss: 44.2490, Time: 0.56s\n",
            "Epoch 13, Loss: 55.8434, Time: 0.47s\n",
            "Epoch 14, Loss: 48.3627, Time: 0.49s\n",
            "\n",
            "[Epoch 15] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.461 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.461 GB\n",
            "Metis partitioning: 0.019 seconds, peak memory: 13.461 GB\n",
            "Epoch 15, Loss: 46.8808, Time: 0.55s\n",
            "Epoch 16, Loss: 52.8705, Time: 0.48s\n",
            "Epoch 17, Loss: 50.6371, Time: 0.47s\n",
            "Epoch 18, Loss: 46.6787, Time: 0.49s\n",
            "Epoch 19, Loss: 49.6529, Time: 0.47s\n",
            "\n",
            "[Epoch 20] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.461 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.461 GB\n",
            "Metis partitioning: 0.018 seconds, peak memory: 13.461 GB\n",
            "Epoch 20, Loss: 44.8302, Time: 0.57s\n",
            "Epoch 21, Loss: 53.4470, Time: 0.47s\n",
            "Epoch 22, Loss: 45.8544, Time: 0.49s\n",
            "Epoch 23, Loss: 46.6046, Time: 0.48s\n",
            "Epoch 24, Loss: 49.5000, Time: 0.47s\n",
            "\n",
            "[Epoch 25] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.461 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.461 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.461 GB\n",
            "Epoch 25, Loss: 50.4614, Time: 0.57s\n",
            "Epoch 26, Loss: 45.2645, Time: 0.47s\n",
            "Epoch 27, Loss: 38.0823, Time: 0.48s\n",
            "Epoch 28, Loss: 46.5280, Time: 0.49s\n",
            "Epoch 29, Loss: 46.6985, Time: 0.48s\n",
            "\n",
            "[Epoch 30] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.461 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.461 GB\n",
            "Metis partitioning: 0.018 seconds, peak memory: 13.461 GB\n",
            "Epoch 30, Loss: 47.6965, Time: 0.58s\n",
            "Epoch 31, Loss: 39.0833, Time: 0.48s\n",
            "Epoch 32, Loss: 51.3080, Time: 0.55s\n",
            "Epoch 33, Loss: 42.3085, Time: 0.59s\n",
            "Epoch 34, Loss: 47.9199, Time: 0.59s\n",
            "\n",
            "[Epoch 35] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.001 seconds, peak memory: 13.461 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.461 GB\n",
            "Metis partitioning: 0.023 seconds, peak memory: 13.461 GB\n",
            "Epoch 35, Loss: 39.0932, Time: 0.71s\n",
            "Epoch 36, Loss: 46.7292, Time: 0.48s\n",
            "Epoch 37, Loss: 41.8657, Time: 0.46s\n",
            "Epoch 38, Loss: 43.8460, Time: 0.47s\n",
            "Epoch 39, Loss: 42.9172, Time: 0.47s\n",
            "\n",
            "[Epoch 40] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.461 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.461 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.461 GB\n",
            "Epoch 40, Loss: 45.0958, Time: 0.58s\n",
            "Epoch 41, Loss: 51.2564, Time: 0.47s\n",
            "Epoch 42, Loss: 40.7466, Time: 0.50s\n",
            "Epoch 43, Loss: 32.0282, Time: 0.48s\n",
            "Epoch 44, Loss: 40.0302, Time: 0.47s\n",
            "\n",
            "[Epoch 45] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.461 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.461 GB\n",
            "Metis partitioning: 0.019 seconds, peak memory: 13.461 GB\n",
            "Epoch 45, Loss: 48.4957, Time: 0.56s\n",
            "Epoch 46, Loss: 43.0695, Time: 0.47s\n",
            "Epoch 47, Loss: 45.6660, Time: 0.48s\n",
            "Epoch 48, Loss: 39.3458, Time: 0.47s\n",
            "Epoch 49, Loss: 41.5884, Time: 0.48s\n",
            "Test Accuracy: 0.811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**SAGE model - CORA**\n"
      ],
      "metadata": {
        "id": "icJtvKAwjuNM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4oQMFtJZZVU",
        "outputId": "3d9d94ec-7c98-4e2f-91ab-07fb70832e35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.326 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.326 GB\n",
            "Metis partitioning: 0.018 seconds, peak memory: 13.326 GB\n",
            "Epoch 0, Loss: 169.3610, Time: 0.31s\n",
            "Epoch 1, Loss: 161.6532, Time: 0.32s\n",
            "Epoch 2, Loss: 154.3731, Time: 0.33s\n",
            "Epoch 3, Loss: 145.6822, Time: 0.31s\n",
            "Epoch 4, Loss: 134.3488, Time: 0.31s\n",
            "\n",
            "[Epoch 5] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.326 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.326 GB\n",
            "Metis partitioning: 0.020 seconds, peak memory: 13.326 GB\n",
            "Epoch 5, Loss: 123.0420, Time: 0.41s\n",
            "Epoch 6, Loss: 110.6501, Time: 0.33s\n",
            "Epoch 7, Loss: 94.5461, Time: 0.30s\n",
            "Epoch 8, Loss: 82.7916, Time: 0.32s\n",
            "Epoch 9, Loss: 69.5157, Time: 0.32s\n",
            "\n",
            "[Epoch 10] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.326 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.326 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.326 GB\n",
            "Epoch 10, Loss: 66.8864, Time: 0.40s\n",
            "Epoch 11, Loss: 54.3839, Time: 0.32s\n",
            "Epoch 12, Loss: 46.0385, Time: 0.31s\n",
            "Epoch 13, Loss: 38.3033, Time: 0.31s\n",
            "Epoch 14, Loss: 33.0979, Time: 0.32s\n",
            "\n",
            "[Epoch 15] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.326 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.326 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.326 GB\n",
            "Epoch 15, Loss: 31.5412, Time: 0.38s\n",
            "Epoch 16, Loss: 24.8816, Time: 0.30s\n",
            "Epoch 17, Loss: 22.1670, Time: 0.31s\n",
            "Epoch 18, Loss: 21.0233, Time: 0.30s\n",
            "Epoch 19, Loss: 16.5786, Time: 0.34s\n",
            "\n",
            "[Epoch 20] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.326 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.326 GB\n",
            "Metis partitioning: 0.024 seconds, peak memory: 13.326 GB\n",
            "Epoch 20, Loss: 15.0159, Time: 0.50s\n",
            "Epoch 21, Loss: 12.3292, Time: 0.37s\n",
            "Epoch 22, Loss: 12.3206, Time: 0.36s\n",
            "Epoch 23, Loss: 11.1366, Time: 0.40s\n",
            "Epoch 24, Loss: 9.7781, Time: 0.41s\n",
            "\n",
            "[Epoch 25] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.326 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.326 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.326 GB\n",
            "Epoch 25, Loss: 9.5110, Time: 0.39s\n",
            "Epoch 26, Loss: 8.5413, Time: 0.31s\n",
            "Epoch 27, Loss: 10.2785, Time: 0.30s\n",
            "Epoch 28, Loss: 7.8529, Time: 0.31s\n",
            "Epoch 29, Loss: 7.7583, Time: 0.31s\n",
            "\n",
            "[Epoch 30] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.326 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.326 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.326 GB\n",
            "Epoch 30, Loss: 5.2627, Time: 0.38s\n",
            "Epoch 31, Loss: 4.5051, Time: 0.30s\n",
            "Epoch 32, Loss: 4.2823, Time: 0.29s\n",
            "Epoch 33, Loss: 4.9652, Time: 0.29s\n",
            "Epoch 34, Loss: 3.9689, Time: 0.29s\n",
            "\n",
            "[Epoch 35] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.326 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.326 GB\n",
            "Metis partitioning: 0.018 seconds, peak memory: 13.326 GB\n",
            "Epoch 35, Loss: 4.3094, Time: 0.39s\n",
            "Epoch 36, Loss: 4.2615, Time: 0.29s\n",
            "Epoch 37, Loss: 4.4727, Time: 0.30s\n",
            "Epoch 38, Loss: 4.7160, Time: 0.30s\n",
            "Epoch 39, Loss: 3.9763, Time: 0.30s\n",
            "\n",
            "[Epoch 40] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.326 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.326 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.326 GB\n",
            "Epoch 40, Loss: 4.0110, Time: 0.38s\n",
            "Epoch 41, Loss: 3.4624, Time: 0.29s\n",
            "Epoch 42, Loss: 2.6027, Time: 0.30s\n",
            "Epoch 43, Loss: 3.0791, Time: 0.29s\n",
            "Epoch 44, Loss: 2.4230, Time: 0.30s\n",
            "\n",
            "[Epoch 45] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.326 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.326 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.326 GB\n",
            "Epoch 45, Loss: 2.4080, Time: 0.41s\n",
            "Epoch 46, Loss: 2.2920, Time: 0.32s\n",
            "Epoch 47, Loss: 1.5500, Time: 0.31s\n",
            "Epoch 48, Loss: 1.5216, Time: 0.31s\n",
            "Epoch 49, Loss: 2.1260, Time: 0.31s\n",
            "Test Accuracy: 0.811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kq187w7k2TBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**CiteSeer**"
      ],
      "metadata": {
        "id": "C0EU7IWti8qO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load citeseer dataset\n",
        "citeseer_dataset = Planetoid(root='data/CiteSeer', name='CiteSeer')\n",
        "citeseer_data = citeseer_dataset[0].to(device)  # Assume only one graph in the dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzwjztnqi8em",
        "outputId": "75834ede-f77d-4f97-acd8-10b0dc6043f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GCN - CiteSeer**\n"
      ],
      "metadata": {
        "id": "Pgr54cLbkYoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = citeseer_data.num_features\n",
        "hidden_dim = 256\n",
        "output_dim = int(citeseer_data.y.max() - citeseer_data.y.min() + 1)\n",
        "# learning_rate = 0.1\n",
        "epochs = 50\n",
        "num_partitions = 128  # Number of partitions for adaptive partitioning\n",
        "partition_interval = 5  # Re-partition every 5 epochs\n",
        "imbalance_threshold = 1.5  # Max allowed partition imbalance ratio\n",
        "\n",
        "# Convert PyG to DGL and apply adaptive partitioning\n",
        "dgl_graph = pyg_to_dgl(citeseer_data)\n",
        "dgl_graph = adaptive_partitioning(dgl_graph, num_partitions=num_partitions, imbalance_threshold=imbalance_threshold)\n",
        "\n",
        "# Copy the partition info back to PyG object for compatibility\n",
        "partition_tensor = dgl_graph.ndata['part'].to(citeseer_data.x.device)\n",
        "citeseer_data.part = partition_tensor\n",
        "\n",
        "train_loaders = create_partition_loaders(citeseer_data, num_partitions, batch_size=128)\n",
        "\n",
        "gcn_model = GCN(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim).to(device)\n",
        "optimizer = torch.optim.Adam(gcn_model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "train_minibatch(gcn_model, citeseer_data, train_loaders, optimizer, criterion, epochs=epochs, partition_interval=partition_interval)\n",
        "test_acc = evaluate(gcn_model, citeseer_data, citeseer_data.test_mask)\n",
        "\n",
        "print(\"Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa8pnacSkYL6",
        "outputId": "b833e623-3ce1-4bba-bef4-fbf2d18ab574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.650 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.650 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.650 GB\n",
            "Epoch 0, Loss: 133.8869, Time: 0.32s\n",
            "Epoch 1, Loss: 120.7798, Time: 0.87s\n",
            "Epoch 2, Loss: 108.6856, Time: 0.70s\n",
            "Epoch 3, Loss: 96.1708, Time: 0.41s\n",
            "Epoch 4, Loss: 83.6712, Time: 0.31s\n",
            "\n",
            "[Epoch 5] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.650 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.650 GB\n",
            "Metis partitioning: 0.018 seconds, peak memory: 13.650 GB\n",
            "Epoch 5, Loss: 71.1657, Time: 0.44s\n",
            "Epoch 6, Loss: 59.2644, Time: 0.32s\n",
            "Epoch 7, Loss: 49.9215, Time: 0.32s\n",
            "Epoch 8, Loss: 40.6654, Time: 0.34s\n",
            "Epoch 9, Loss: 34.5397, Time: 0.43s\n",
            "\n",
            "[Epoch 10] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.001 seconds, peak memory: 13.650 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.650 GB\n",
            "Metis partitioning: 0.026 seconds, peak memory: 13.650 GB\n",
            "Epoch 10, Loss: 28.7346, Time: 0.53s\n",
            "Epoch 11, Loss: 23.5972, Time: 0.36s\n",
            "Epoch 12, Loss: 20.0016, Time: 0.39s\n",
            "Epoch 13, Loss: 16.8141, Time: 0.43s\n",
            "Epoch 14, Loss: 14.6098, Time: 0.36s\n",
            "\n",
            "[Epoch 15] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.650 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.650 GB\n",
            "Metis partitioning: 0.018 seconds, peak memory: 13.650 GB\n",
            "Epoch 15, Loss: 16.6418, Time: 0.47s\n",
            "Epoch 16, Loss: 13.3384, Time: 0.35s\n",
            "Epoch 17, Loss: 11.2056, Time: 0.35s\n",
            "Epoch 18, Loss: 9.6321, Time: 0.35s\n",
            "Epoch 19, Loss: 8.5916, Time: 0.35s\n",
            "\n",
            "[Epoch 20] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.650 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.650 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.650 GB\n",
            "Epoch 20, Loss: 6.6559, Time: 0.44s\n",
            "Epoch 21, Loss: 5.7766, Time: 0.32s\n",
            "Epoch 22, Loss: 5.3478, Time: 0.32s\n",
            "Epoch 23, Loss: 4.8395, Time: 0.32s\n",
            "Epoch 24, Loss: 4.2946, Time: 0.32s\n",
            "\n",
            "[Epoch 25] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.651 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.651 GB\n",
            "Metis partitioning: 0.018 seconds, peak memory: 13.651 GB\n",
            "Epoch 25, Loss: 4.5585, Time: 0.46s\n",
            "Epoch 26, Loss: 4.2004, Time: 0.33s\n",
            "Epoch 27, Loss: 3.7203, Time: 0.33s\n",
            "Epoch 28, Loss: 3.4001, Time: 0.34s\n",
            "Epoch 29, Loss: 3.1561, Time: 0.33s\n",
            "\n",
            "[Epoch 30] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.651 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.651 GB\n",
            "Metis partitioning: 0.018 seconds, peak memory: 13.651 GB\n",
            "Epoch 30, Loss: 2.5982, Time: 0.43s\n",
            "Epoch 31, Loss: 2.2447, Time: 0.32s\n",
            "Epoch 32, Loss: 2.1595, Time: 0.32s\n",
            "Epoch 33, Loss: 2.0833, Time: 0.31s\n",
            "Epoch 34, Loss: 1.8716, Time: 0.32s\n",
            "\n",
            "[Epoch 35] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.651 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.651 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.651 GB\n",
            "Epoch 35, Loss: 1.7671, Time: 0.43s\n",
            "Epoch 36, Loss: 1.5903, Time: 0.31s\n",
            "Epoch 37, Loss: 1.5709, Time: 0.32s\n",
            "Epoch 38, Loss: 1.4808, Time: 0.31s\n",
            "Epoch 39, Loss: 1.4064, Time: 0.31s\n",
            "\n",
            "[Epoch 40] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.651 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.651 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.651 GB\n",
            "Epoch 40, Loss: 1.3197, Time: 0.43s\n",
            "Epoch 41, Loss: 1.1614, Time: 0.31s\n",
            "Epoch 42, Loss: 1.1179, Time: 0.32s\n",
            "Epoch 43, Loss: 1.1171, Time: 0.42s\n",
            "Epoch 44, Loss: 1.0143, Time: 0.38s\n",
            "\n",
            "[Epoch 45] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.001 seconds, peak memory: 13.651 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.651 GB\n",
            "Metis partitioning: 0.027 seconds, peak memory: 13.651 GB\n",
            "Epoch 45, Loss: 1.1567, Time: 0.55s\n",
            "Epoch 46, Loss: 1.0440, Time: 0.41s\n",
            "Epoch 47, Loss: 0.9500, Time: 0.45s\n",
            "Epoch 48, Loss: 0.8746, Time: 0.36s\n",
            "Epoch 49, Loss: 0.8068, Time: 0.33s\n",
            "Test Accuracy: 0.681\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GAT-CiteSeer**"
      ],
      "metadata": {
        "id": "5O8VF2-Yk4XD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = citeseer_data.num_features\n",
        "hidden_dim = 256\n",
        "output_dim = int(citeseer_data.y.max() - citeseer_data.y.min() + 1)\n",
        "# learning_rate = 0.1\n",
        "epochs = 50\n",
        "num_partitions = 128  # Number of partitions for adaptive partitioning\n",
        "partition_interval = 5  # Re-partition every 5 epochs\n",
        "imbalance_threshold = 1.5  # Max allowed partition imbalance ratio\n",
        "\n",
        "# Convert PyG to DGL and apply adaptive partitioning\n",
        "dgl_graph = pyg_to_dgl(citeseer_data)\n",
        "dgl_graph = adaptive_partitioning(dgl_graph, num_partitions=num_partitions, imbalance_threshold=imbalance_threshold)\n",
        "\n",
        "# Copy the partition info back to PyG object for compatibility\n",
        "partition_tensor = dgl_graph.ndata['part'].to(citeseer_data.x.device)\n",
        "citeseer_data.part = partition_tensor\n",
        "\n",
        "train_loaders = create_partition_loaders(citeseer_data, num_partitions, batch_size=128)\n",
        "\n",
        "gat_model = GAT(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim).to(device)\n",
        "optimizer = torch.optim.Adam(gat_model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "train_minibatch(gat_model, citeseer_data, train_loaders, optimizer, criterion, epochs=epochs, partition_interval=partition_interval)\n",
        "test_acc = evaluate(gat_model, citeseer_data, citeseer_data.test_mask)\n",
        "\n",
        "print(\"Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foooKAT4jRH5",
        "outputId": "633c95e4-9422-4f83-a2c8-3223af61bd66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.933 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.933 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.933 GB\n",
            "Epoch 0, Loss: 135.6477, Time: 0.62s\n",
            "Epoch 1, Loss: 127.6758, Time: 0.62s\n",
            "Epoch 2, Loss: 118.5697, Time: 0.60s\n",
            "Epoch 3, Loss: 112.2784, Time: 0.61s\n",
            "Epoch 4, Loss: 104.5411, Time: 0.60s\n",
            "\n",
            "[Epoch 5] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.933 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.933 GB\n",
            "Metis partitioning: 0.021 seconds, peak memory: 13.933 GB\n",
            "Epoch 5, Loss: 99.8715, Time: 0.71s\n",
            "Epoch 6, Loss: 89.6498, Time: 0.59s\n",
            "Epoch 7, Loss: 80.8371, Time: 0.59s\n",
            "Epoch 8, Loss: 70.5256, Time: 0.60s\n",
            "Epoch 9, Loss: 73.1796, Time: 0.60s\n",
            "\n",
            "[Epoch 10] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.933 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.933 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.933 GB\n",
            "Epoch 10, Loss: 66.4660, Time: 0.74s\n",
            "Epoch 11, Loss: 70.3506, Time: 0.61s\n",
            "Epoch 12, Loss: 64.4013, Time: 0.60s\n",
            "Epoch 13, Loss: 68.9170, Time: 0.72s\n",
            "Epoch 14, Loss: 58.1383, Time: 0.71s\n",
            "\n",
            "[Epoch 15] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.001 seconds, peak memory: 13.933 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.933 GB\n",
            "Metis partitioning: 0.025 seconds, peak memory: 13.933 GB\n",
            "Epoch 15, Loss: 68.5799, Time: 0.99s\n",
            "Epoch 16, Loss: 53.5459, Time: 0.84s\n",
            "Epoch 17, Loss: 50.9555, Time: 0.62s\n",
            "Epoch 18, Loss: 50.3267, Time: 0.60s\n",
            "Epoch 19, Loss: 46.0091, Time: 0.74s\n",
            "\n",
            "[Epoch 20] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.933 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.933 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.933 GB\n",
            "Epoch 20, Loss: 55.9558, Time: 0.75s\n",
            "Epoch 21, Loss: 50.5522, Time: 0.61s\n",
            "Epoch 22, Loss: 51.3524, Time: 0.60s\n",
            "Epoch 23, Loss: 47.7473, Time: 0.63s\n",
            "Epoch 24, Loss: 46.7392, Time: 0.63s\n",
            "\n",
            "[Epoch 25] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.933 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.933 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.933 GB\n",
            "Epoch 25, Loss: 46.0519, Time: 0.74s\n",
            "Epoch 26, Loss: 41.1629, Time: 0.62s\n",
            "Epoch 27, Loss: 48.1222, Time: 0.61s\n",
            "Epoch 28, Loss: 57.9398, Time: 0.62s\n",
            "Epoch 29, Loss: 44.9816, Time: 0.61s\n",
            "\n",
            "[Epoch 30] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.001 seconds, peak memory: 13.933 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.933 GB\n",
            "Metis partitioning: 0.018 seconds, peak memory: 13.933 GB\n",
            "Epoch 30, Loss: 46.9958, Time: 0.71s\n",
            "Epoch 31, Loss: 46.1932, Time: 0.72s\n",
            "Epoch 32, Loss: 43.5453, Time: 0.70s\n",
            "Epoch 33, Loss: 47.6325, Time: 0.74s\n",
            "Epoch 34, Loss: 44.7213, Time: 0.67s\n",
            "\n",
            "[Epoch 35] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.933 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.933 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.933 GB\n",
            "Epoch 35, Loss: 41.9127, Time: 0.68s\n",
            "Epoch 36, Loss: 32.7321, Time: 0.57s\n",
            "Epoch 37, Loss: 36.1988, Time: 0.58s\n",
            "Epoch 38, Loss: 44.8749, Time: 0.57s\n",
            "Epoch 39, Loss: 40.5274, Time: 0.58s\n",
            "\n",
            "[Epoch 40] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.933 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.933 GB\n",
            "Metis partitioning: 0.016 seconds, peak memory: 13.933 GB\n",
            "Epoch 40, Loss: 39.6569, Time: 0.71s\n",
            "Epoch 41, Loss: 41.1555, Time: 0.61s\n",
            "Epoch 42, Loss: 46.4343, Time: 0.61s\n",
            "Epoch 43, Loss: 40.1630, Time: 0.62s\n",
            "Epoch 44, Loss: 37.0298, Time: 0.61s\n",
            "\n",
            "[Epoch 45] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.933 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.933 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.933 GB\n",
            "Epoch 45, Loss: 29.6053, Time: 0.71s\n",
            "Epoch 46, Loss: 34.8746, Time: 0.60s\n",
            "Epoch 47, Loss: 40.6003, Time: 0.61s\n",
            "Epoch 48, Loss: 36.9599, Time: 0.59s\n",
            "Epoch 49, Loss: 40.7819, Time: 0.61s\n",
            "Test Accuracy: 0.679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**SAGE-CiteSeer**"
      ],
      "metadata": {
        "id": "VvRpm2B3k7-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = citeseer_data.num_features\n",
        "hidden_dim = 256\n",
        "output_dim = int(citeseer_data.y.max() - citeseer_data.y.min() + 1)\n",
        "# learning_rate = 0.1\n",
        "epochs = 50\n",
        "num_partitions = 128  # Number of partitions for adaptive partitioning\n",
        "partition_interval = 5  # Re-partition every 5 epochs\n",
        "imbalance_threshold = 1.5  # Max allowed partition imbalance ratio\n",
        "\n",
        "# Convert PyG to DGL and apply adaptive partitioning\n",
        "dgl_graph = pyg_to_dgl(citeseer_data)\n",
        "dgl_graph = adaptive_partitioning(dgl_graph, num_partitions=num_partitions, imbalance_threshold=imbalance_threshold)\n",
        "\n",
        "# Copy the partition info back to PyG object for compatibility\n",
        "partition_tensor = dgl_graph.ndata['part'].to(citeseer_data.x.device)\n",
        "citeseer_data.part = partition_tensor\n",
        "\n",
        "train_loaders = create_partition_loaders(citeseer_data, num_partitions, batch_size=128)\n",
        "\n",
        "sage_model = GraphSAGE(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim).to(device)\n",
        "optimizer = torch.optim.Adam(sage_model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "train_minibatch(sage_model, citeseer_data, train_loaders, optimizer, criterion, epochs=epochs, partition_interval=partition_interval)\n",
        "test_acc = evaluate(sage_model, citeseer_data, citeseer_data.test_mask)\n",
        "\n",
        "print(\"Test Accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2C6iKLxbk-zE",
        "outputId": "a9cf948e-e8fd-4ec7-a558-176958281888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert a graph into a bidirected graph: 0.001 seconds, peak memory: 13.935 GB\n",
            "Construct multi-constraint weights: 0.001 seconds, peak memory: 13.935 GB\n",
            "Metis partitioning: 0.026 seconds, peak memory: 13.935 GB\n",
            "Epoch 0, Loss: 134.4818, Time: 0.40s\n",
            "Epoch 1, Loss: 124.9051, Time: 0.32s\n",
            "Epoch 2, Loss: 114.7484, Time: 0.30s\n",
            "Epoch 3, Loss: 102.1520, Time: 0.29s\n",
            "Epoch 4, Loss: 87.2902, Time: 0.30s\n",
            "\n",
            "[Epoch 5] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.935 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.935 GB\n",
            "Metis partitioning: 0.019 seconds, peak memory: 13.935 GB\n",
            "Epoch 5, Loss: 70.7696, Time: 0.42s\n",
            "Epoch 6, Loss: 57.4887, Time: 0.29s\n",
            "Epoch 7, Loss: 43.9011, Time: 0.29s\n",
            "Epoch 8, Loss: 33.8285, Time: 0.29s\n",
            "Epoch 9, Loss: 27.4696, Time: 0.30s\n",
            "\n",
            "[Epoch 10] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.935 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.935 GB\n",
            "Metis partitioning: 0.016 seconds, peak memory: 13.935 GB\n",
            "Epoch 10, Loss: 23.7772, Time: 0.41s\n",
            "Epoch 11, Loss: 18.5073, Time: 0.29s\n",
            "Epoch 12, Loss: 15.2349, Time: 0.30s\n",
            "Epoch 13, Loss: 12.4792, Time: 0.29s\n",
            "Epoch 14, Loss: 10.1617, Time: 0.29s\n",
            "\n",
            "[Epoch 15] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.935 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.935 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.935 GB\n",
            "Epoch 15, Loss: 9.8150, Time: 0.42s\n",
            "Epoch 16, Loss: 7.6080, Time: 0.29s\n",
            "Epoch 17, Loss: 7.0233, Time: 0.29s\n",
            "Epoch 18, Loss: 6.0397, Time: 0.36s\n",
            "Epoch 19, Loss: 5.4142, Time: 0.55s\n",
            "\n",
            "[Epoch 20] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.935 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.935 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.935 GB\n",
            "Epoch 20, Loss: 5.1610, Time: 0.46s\n",
            "Epoch 21, Loss: 3.6618, Time: 0.55s\n",
            "Epoch 22, Loss: 3.7873, Time: 0.30s\n",
            "Epoch 23, Loss: 3.0498, Time: 0.58s\n",
            "Epoch 24, Loss: 2.8191, Time: 0.29s\n",
            "\n",
            "[Epoch 25] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.935 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.935 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.935 GB\n",
            "Epoch 25, Loss: 3.6018, Time: 0.44s\n",
            "Epoch 26, Loss: 3.3133, Time: 0.33s\n",
            "Epoch 27, Loss: 3.0163, Time: 0.32s\n",
            "Epoch 28, Loss: 2.8913, Time: 0.32s\n",
            "Epoch 29, Loss: 2.3037, Time: 0.35s\n",
            "\n",
            "[Epoch 30] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.001 seconds, peak memory: 13.935 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.935 GB\n",
            "Metis partitioning: 0.021 seconds, peak memory: 13.935 GB\n",
            "Epoch 30, Loss: 2.3714, Time: 0.55s\n",
            "Epoch 31, Loss: 2.0195, Time: 0.37s\n",
            "Epoch 32, Loss: 1.8556, Time: 0.36s\n",
            "Epoch 33, Loss: 1.9222, Time: 0.41s\n",
            "Epoch 34, Loss: 1.5626, Time: 0.42s\n",
            "\n",
            "[Epoch 35] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.935 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.935 GB\n",
            "Metis partitioning: 0.017 seconds, peak memory: 13.935 GB\n",
            "Epoch 35, Loss: 1.4580, Time: 0.41s\n",
            "Epoch 36, Loss: 1.2199, Time: 0.29s\n",
            "Epoch 37, Loss: 1.2748, Time: 0.29s\n",
            "Epoch 38, Loss: 1.0413, Time: 0.29s\n",
            "Epoch 39, Loss: 1.1258, Time: 0.29s\n",
            "\n",
            "[Epoch 40] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.935 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.935 GB\n",
            "Metis partitioning: 0.016 seconds, peak memory: 13.935 GB\n",
            "Epoch 40, Loss: 1.0033, Time: 0.41s\n",
            "Epoch 41, Loss: 0.7861, Time: 0.29s\n",
            "Epoch 42, Loss: 0.8275, Time: 0.29s\n",
            "Epoch 43, Loss: 0.8458, Time: 0.30s\n",
            "Epoch 44, Loss: 0.8132, Time: 0.31s\n",
            "\n",
            "[Epoch 45] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.000 seconds, peak memory: 13.935 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 13.935 GB\n",
            "Metis partitioning: 0.018 seconds, peak memory: 13.935 GB\n",
            "Epoch 45, Loss: 0.5692, Time: 0.41s\n",
            "Epoch 46, Loss: 0.6080, Time: 0.30s\n",
            "Epoch 47, Loss: 0.5594, Time: 0.29s\n",
            "Epoch 48, Loss: 0.5685, Time: 0.29s\n",
            "Epoch 49, Loss: 0.4300, Time: 0.29s\n",
            "Test Accuracy: 0.693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p86gyRCumMis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Pubmed**"
      ],
      "metadata": {
        "id": "_ZL5a2nAnXTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load PubMed dataset\n",
        "pubmed_dataset = Planetoid(root='data/PubMed', name='PubMed')\n",
        "pubmed_data = pubmed_dataset[0].to(device)  # Assume only one graph in the dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUzGJxJSnenp",
        "outputId": "cdd3c38d-5e04-4cad-8b56-9245d2d77f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GCN-Pubmed**"
      ],
      "metadata": {
        "id": "zSH7DiZmnqKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = pubmed_data.num_features\n",
        "hidden_dim = 64\n",
        "output_dim = int(pubmed_data.y.max() - pubmed_data.y.min() + 1)\n",
        "# learning_rate = 0.1\n",
        "epochs = 50\n",
        "num_partitions = 128  # Number of partitions for adaptive partitioning\n",
        "partition_interval = 5  # Re-partition every 5 epochs\n",
        "imbalance_threshold = 1.5  # Max allowed partition imbalance ratio\n",
        "\n",
        "# Convert PyG to DGL and apply adaptive partitioning\n",
        "dgl_graph = pyg_to_dgl(pubmed_data)\n",
        "dgl_graph = adaptive_partitioning(dgl_graph, num_partitions=num_partitions, imbalance_threshold=imbalance_threshold)\n",
        "\n",
        "# Copy the partition info back to PyG object for compatibility\n",
        "partition_tensor = dgl_graph.ndata['part'].to(pubmed_data.x.device)\n",
        "pubmed_data.part = partition_tensor\n",
        "\n",
        "train_loaders = create_partition_loaders(pubmed_data, num_partitions, batch_size=64)\n",
        "\n",
        "gcn_model = GCN(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim).to(device)\n",
        "optimizer = torch.optim.Adam(gcn_model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "train_minibatch(gcn_model, pubmed_data, train_loaders, optimizer, criterion, epochs=epochs, partition_interval=partition_interval)\n",
        "test_acc = evaluate(gcn_model, pubmed_data, pubmed_data.test_mask)\n",
        "\n",
        "print(\"Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5wi_xybnpUT",
        "outputId": "974583c3-485b-4a16-a104-5521340f1042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 18.680 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 18.680 GB\n",
            "Metis partitioning: 0.057 seconds, peak memory: 18.680 GB\n",
            "Epoch 0, Loss: 57.0572, Time: 0.19s\n",
            "Epoch 1, Loss: 54.6426, Time: 0.19s\n",
            "Epoch 2, Loss: 51.2024, Time: 0.19s\n",
            "Epoch 3, Loss: 46.7737, Time: 0.24s\n",
            "Epoch 4, Loss: 41.7061, Time: 0.19s\n",
            "\n",
            "[Epoch 5] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.004 seconds, peak memory: 18.680 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 18.680 GB\n",
            "Metis partitioning: 0.055 seconds, peak memory: 18.680 GB\n",
            "Epoch 5, Loss: 36.9964, Time: 0.34s\n",
            "Epoch 6, Loss: 32.0261, Time: 0.19s\n",
            "Epoch 7, Loss: 28.1203, Time: 0.20s\n",
            "Epoch 8, Loss: 24.8917, Time: 0.19s\n",
            "Epoch 9, Loss: 21.1926, Time: 0.19s\n",
            "\n",
            "[Epoch 10] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 18.680 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 18.680 GB\n",
            "Metis partitioning: 0.063 seconds, peak memory: 18.680 GB\n",
            "Epoch 10, Loss: 19.6338, Time: 0.38s\n",
            "Epoch 11, Loss: 17.2634, Time: 0.21s\n",
            "Epoch 12, Loss: 14.8422, Time: 0.21s\n",
            "Epoch 13, Loss: 14.0081, Time: 0.19s\n",
            "Epoch 14, Loss: 12.1957, Time: 0.20s\n",
            "\n",
            "[Epoch 15] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.004 seconds, peak memory: 18.721 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 18.721 GB\n",
            "Metis partitioning: 0.058 seconds, peak memory: 18.721 GB\n",
            "Epoch 15, Loss: 10.9872, Time: 0.41s\n",
            "Epoch 16, Loss: 10.4356, Time: 0.20s\n",
            "Epoch 17, Loss: 9.0282, Time: 0.19s\n",
            "Epoch 18, Loss: 8.7863, Time: 0.19s\n",
            "Epoch 19, Loss: 8.2251, Time: 0.19s\n",
            "\n",
            "[Epoch 20] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.004 seconds, peak memory: 18.790 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 18.790 GB\n",
            "Metis partitioning: 0.057 seconds, peak memory: 18.790 GB\n",
            "Epoch 20, Loss: 7.1821, Time: 0.42s\n",
            "Epoch 21, Loss: 6.3534, Time: 0.19s\n",
            "Epoch 22, Loss: 5.6966, Time: 0.20s\n",
            "Epoch 23, Loss: 5.9674, Time: 0.19s\n",
            "Epoch 24, Loss: 5.8793, Time: 0.20s\n",
            "\n",
            "[Epoch 25] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.004 seconds, peak memory: 18.858 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 18.858 GB\n",
            "Metis partitioning: 0.056 seconds, peak memory: 18.858 GB\n",
            "Epoch 25, Loss: 5.2431, Time: 0.39s\n",
            "Epoch 26, Loss: 4.9437, Time: 0.19s\n",
            "Epoch 27, Loss: 4.8328, Time: 0.26s\n",
            "Epoch 28, Loss: 4.3129, Time: 0.25s\n",
            "Epoch 29, Loss: 3.9420, Time: 0.25s\n",
            "\n",
            "[Epoch 30] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 18.858 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 18.858 GB\n",
            "Metis partitioning: 0.075 seconds, peak memory: 18.858 GB\n",
            "Epoch 30, Loss: 3.5017, Time: 0.41s\n",
            "Epoch 31, Loss: 3.4005, Time: 0.23s\n",
            "Epoch 32, Loss: 3.7108, Time: 0.26s\n",
            "Epoch 33, Loss: 3.7810, Time: 0.28s\n",
            "Epoch 34, Loss: 3.1821, Time: 0.27s\n",
            "\n",
            "[Epoch 35] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 18.858 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 18.858 GB\n",
            "Metis partitioning: 0.056 seconds, peak memory: 18.858 GB\n",
            "Epoch 35, Loss: 3.0127, Time: 0.34s\n",
            "Epoch 36, Loss: 3.4353, Time: 0.20s\n",
            "Epoch 37, Loss: 3.3795, Time: 0.20s\n",
            "Epoch 38, Loss: 3.5700, Time: 0.20s\n",
            "Epoch 39, Loss: 3.3725, Time: 0.19s\n",
            "\n",
            "[Epoch 40] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 18.858 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 18.858 GB\n",
            "Metis partitioning: 0.057 seconds, peak memory: 18.858 GB\n",
            "Epoch 40, Loss: 2.8681, Time: 0.34s\n",
            "Epoch 41, Loss: 2.7595, Time: 0.21s\n",
            "Epoch 42, Loss: 2.5011, Time: 0.19s\n",
            "Epoch 43, Loss: 2.5013, Time: 0.20s\n",
            "Epoch 44, Loss: 2.5296, Time: 0.20s\n",
            "\n",
            "[Epoch 45] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 18.858 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 18.858 GB\n",
            "Metis partitioning: 0.057 seconds, peak memory: 18.858 GB\n",
            "Epoch 45, Loss: 2.4672, Time: 0.35s\n",
            "Epoch 46, Loss: 2.0286, Time: 0.20s\n",
            "Epoch 47, Loss: 2.1024, Time: 0.19s\n",
            "Epoch 48, Loss: 2.2379, Time: 0.20s\n",
            "Epoch 49, Loss: 2.0426, Time: 0.19s\n",
            "Test Accuracy: 0.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GAT-Pubmed**"
      ],
      "metadata": {
        "id": "_Vfc4fIUnv2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = pubmed_data.num_features\n",
        "hidden_dim = 64\n",
        "output_dim = int(pubmed_data.y.max() - pubmed_data.y.min() + 1)\n",
        "# learning_rate = 0.1\n",
        "epochs = 50\n",
        "num_partitions = 128  # Number of partitions for adaptive partitioning\n",
        "partition_interval = 5  # Re-partition every 5 epochs\n",
        "imbalance_threshold = 1.5  # Max allowed partition imbalance ratio\n",
        "\n",
        "# Convert PyG to DGL and apply adaptive partitioning\n",
        "dgl_graph = pyg_to_dgl(pubmed_data)\n",
        "dgl_graph = adaptive_partitioning(dgl_graph, num_partitions=num_partitions, imbalance_threshold=imbalance_threshold)\n",
        "\n",
        "# Copy the partition info back to PyG object for compatibility\n",
        "partition_tensor = dgl_graph.ndata['part'].to(pubmed_data.x.device)\n",
        "pubmed_data.part = partition_tensor\n",
        "\n",
        "train_loaders = create_partition_loaders(pubmed_data, num_partitions, batch_size=64)\n",
        "\n",
        "gat_model = GAT(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim).to(device)\n",
        "optimizer = torch.optim.Adam(gat_model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "train_minibatch(gat_model, pubmed_data, train_loaders, optimizer, criterion, epochs=epochs, partition_interval=partition_interval)\n",
        "test_acc = evaluate(gat_model, pubmed_data, pubmed_data.test_mask)\n",
        "\n",
        "print(\"Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qfUUKaZnyne",
        "outputId": "a1dd17ce-071e-4f00-82d3-be3c230fc26d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 19.988 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 19.988 GB\n",
            "Metis partitioning: 0.063 seconds, peak memory: 19.988 GB\n",
            "Epoch 0, Loss: 57.2277, Time: 0.30s\n",
            "Epoch 1, Loss: 55.8392, Time: 0.31s\n",
            "Epoch 2, Loss: 53.3572, Time: 0.31s\n",
            "Epoch 3, Loss: 51.0175, Time: 0.29s\n",
            "Epoch 4, Loss: 46.3050, Time: 0.29s\n",
            "\n",
            "[Epoch 5] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 19.988 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 19.988 GB\n",
            "Metis partitioning: 0.058 seconds, peak memory: 19.988 GB\n",
            "Epoch 5, Loss: 43.6870, Time: 0.46s\n",
            "Epoch 6, Loss: 37.6944, Time: 0.30s\n",
            "Epoch 7, Loss: 36.8989, Time: 0.29s\n",
            "Epoch 8, Loss: 39.3339, Time: 0.31s\n",
            "Epoch 9, Loss: 30.8787, Time: 0.29s\n",
            "\n",
            "[Epoch 10] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 19.988 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 19.988 GB\n",
            "Metis partitioning: 0.056 seconds, peak memory: 19.988 GB\n",
            "Epoch 10, Loss: 27.6891, Time: 0.43s\n",
            "Epoch 11, Loss: 30.9799, Time: 0.29s\n",
            "Epoch 12, Loss: 28.4194, Time: 0.29s\n",
            "Epoch 13, Loss: 32.8251, Time: 0.28s\n",
            "Epoch 14, Loss: 26.9242, Time: 0.30s\n",
            "\n",
            "[Epoch 15] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 19.988 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 19.988 GB\n",
            "Metis partitioning: 0.056 seconds, peak memory: 19.988 GB\n",
            "Epoch 15, Loss: 28.1099, Time: 0.47s\n",
            "Epoch 16, Loss: 23.6645, Time: 0.41s\n",
            "Epoch 17, Loss: 23.8277, Time: 0.38s\n",
            "Epoch 18, Loss: 24.2951, Time: 0.39s\n",
            "Epoch 19, Loss: 27.1326, Time: 0.35s\n",
            "\n",
            "[Epoch 20] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.005 seconds, peak memory: 20.051 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 20.051 GB\n",
            "Metis partitioning: 0.079 seconds, peak memory: 20.051 GB\n",
            "Epoch 20, Loss: 26.6806, Time: 0.69s\n",
            "Epoch 21, Loss: 18.7199, Time: 0.32s\n",
            "Epoch 22, Loss: 24.3715, Time: 0.29s\n",
            "Epoch 23, Loss: 22.3575, Time: 0.28s\n",
            "Epoch 24, Loss: 22.8529, Time: 0.29s\n",
            "\n",
            "[Epoch 25] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.004 seconds, peak memory: 20.119 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 20.119 GB\n",
            "Metis partitioning: 0.056 seconds, peak memory: 20.119 GB\n",
            "Epoch 25, Loss: 18.6911, Time: 0.50s\n",
            "Epoch 26, Loss: 24.8419, Time: 0.29s\n",
            "Epoch 27, Loss: 20.3613, Time: 0.30s\n",
            "Epoch 28, Loss: 22.6076, Time: 0.31s\n",
            "Epoch 29, Loss: 22.6416, Time: 0.29s\n",
            "\n",
            "[Epoch 30] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.004 seconds, peak memory: 20.188 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 20.188 GB\n",
            "Metis partitioning: 0.057 seconds, peak memory: 20.188 GB\n",
            "Epoch 30, Loss: 17.6839, Time: 0.51s\n",
            "Epoch 31, Loss: 17.8570, Time: 0.30s\n",
            "Epoch 32, Loss: 17.8229, Time: 0.30s\n",
            "Epoch 33, Loss: 23.1871, Time: 0.30s\n",
            "Epoch 34, Loss: 20.1153, Time: 0.32s\n",
            "\n",
            "[Epoch 35] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 20.188 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 20.188 GB\n",
            "Metis partitioning: 0.058 seconds, peak memory: 20.188 GB\n",
            "Epoch 35, Loss: 18.0696, Time: 0.45s\n",
            "Epoch 36, Loss: 23.1398, Time: 0.31s\n",
            "Epoch 37, Loss: 15.8652, Time: 0.31s\n",
            "Epoch 38, Loss: 18.3068, Time: 0.30s\n",
            "Epoch 39, Loss: 17.9737, Time: 0.30s\n",
            "\n",
            "[Epoch 40] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 20.188 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 20.188 GB\n",
            "Metis partitioning: 0.058 seconds, peak memory: 20.188 GB\n",
            "Epoch 40, Loss: 15.4777, Time: 0.46s\n",
            "Epoch 41, Loss: 17.7448, Time: 0.29s\n",
            "Epoch 42, Loss: 16.7765, Time: 0.31s\n",
            "Epoch 43, Loss: 14.1001, Time: 0.32s\n",
            "Epoch 44, Loss: 20.7416, Time: 0.29s\n",
            "\n",
            "[Epoch 45] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 20.188 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 20.188 GB\n",
            "Metis partitioning: 0.056 seconds, peak memory: 20.188 GB\n",
            "Epoch 45, Loss: 18.0679, Time: 0.44s\n",
            "Epoch 46, Loss: 20.0509, Time: 0.32s\n",
            "Epoch 47, Loss: 20.2541, Time: 0.30s\n",
            "Epoch 48, Loss: 17.1976, Time: 0.30s\n",
            "Epoch 49, Loss: 19.4330, Time: 0.30s\n",
            "Test Accuracy: 0.773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**SAGE-Pubmed**"
      ],
      "metadata": {
        "id": "QCC-ZtDQnz40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = pubmed_data.num_features\n",
        "hidden_dim = 128\n",
        "output_dim = int(pubmed_data.y.max() - pubmed_data.y.min() + 1)\n",
        "# learning_rate = 0.1\n",
        "epochs = 50\n",
        "num_partitions = 128  # Number of partitions for adaptive partitioning\n",
        "partition_interval = 5  # Re-partition every 5 epochs\n",
        "imbalance_threshold = 1.5  # Max allowed partition imbalance ratio\n",
        "\n",
        "# Convert PyG to DGL and apply adaptive partitioning\n",
        "dgl_graph = pyg_to_dgl(pubmed_data)\n",
        "dgl_graph = adaptive_partitioning(dgl_graph, num_partitions=num_partitions, imbalance_threshold=imbalance_threshold)\n",
        "\n",
        "# Copy the partition info back to PyG object for compatibility\n",
        "partition_tensor = dgl_graph.ndata['part'].to(pubmed_data.x.device)\n",
        "pubmed_data.part = partition_tensor\n",
        "\n",
        "train_loaders = create_partition_loaders(pubmed_data, num_partitions, batch_size=64)\n",
        "\n",
        "sage_model = GraphSAGE(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim).to(device)\n",
        "optimizer = torch.optim.Adam(sage_model.parameters(), lr=0.001, weight_decay = 5e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "train_minibatch(sage_model, pubmed_data, train_loaders, optimizer, criterion, epochs=epochs, partition_interval=partition_interval)\n",
        "test_acc = evaluate(sage_model, pubmed_data, pubmed_data.test_mask)\n",
        "\n",
        "print(\"Test Accuracy:\", test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06aUODIvn1ac",
        "outputId": "fd181071-9c30-439f-9a76-8d3e148d2131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 23.006 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 23.006 GB\n",
            "Metis partitioning: 0.055 seconds, peak memory: 23.006 GB\n",
            "Epoch 0, Loss: 57.1300, Time: 0.19s\n",
            "Epoch 1, Loss: 55.4701, Time: 0.18s\n",
            "Epoch 2, Loss: 52.4399, Time: 0.18s\n",
            "Epoch 3, Loss: 47.8319, Time: 0.19s\n",
            "Epoch 4, Loss: 41.2092, Time: 0.23s\n",
            "\n",
            "[Epoch 5] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 23.006 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 23.006 GB\n",
            "Metis partitioning: 0.076 seconds, peak memory: 23.006 GB\n",
            "Epoch 5, Loss: 33.7639, Time: 0.42s\n",
            "Epoch 6, Loss: 26.3176, Time: 0.21s\n",
            "Epoch 7, Loss: 20.5659, Time: 0.19s\n",
            "Epoch 8, Loss: 15.9906, Time: 0.20s\n",
            "Epoch 9, Loss: 12.7823, Time: 0.24s\n",
            "\n",
            "[Epoch 10] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.004 seconds, peak memory: 23.006 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 23.006 GB\n",
            "Metis partitioning: 0.075 seconds, peak memory: 23.006 GB\n",
            "Epoch 10, Loss: 10.1623, Time: 0.47s\n",
            "Epoch 11, Loss: 8.4981, Time: 0.21s\n",
            "Epoch 12, Loss: 6.8610, Time: 0.17s\n",
            "Epoch 13, Loss: 5.9443, Time: 0.18s\n",
            "Epoch 14, Loss: 4.9179, Time: 0.17s\n",
            "\n",
            "[Epoch 15] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 23.006 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 23.006 GB\n",
            "Metis partitioning: 0.057 seconds, peak memory: 23.006 GB\n",
            "Epoch 15, Loss: 4.2818, Time: 0.35s\n",
            "Epoch 16, Loss: 3.8627, Time: 0.17s\n",
            "Epoch 17, Loss: 3.4270, Time: 0.18s\n",
            "Epoch 18, Loss: 3.7440, Time: 0.18s\n",
            "Epoch 19, Loss: 3.2857, Time: 0.17s\n",
            "\n",
            "[Epoch 20] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.004 seconds, peak memory: 23.006 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 23.006 GB\n",
            "Metis partitioning: 0.059 seconds, peak memory: 23.006 GB\n",
            "Epoch 20, Loss: 2.5742, Time: 0.35s\n",
            "Epoch 21, Loss: 2.7358, Time: 0.17s\n",
            "Epoch 22, Loss: 2.4382, Time: 0.17s\n",
            "Epoch 23, Loss: 2.2398, Time: 0.18s\n",
            "Epoch 24, Loss: 1.9201, Time: 0.17s\n",
            "\n",
            "[Epoch 25] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 23.006 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 23.006 GB\n",
            "Metis partitioning: 0.055 seconds, peak memory: 23.006 GB\n",
            "Epoch 25, Loss: 1.9398, Time: 0.35s\n",
            "Epoch 26, Loss: 2.1473, Time: 0.17s\n",
            "Epoch 27, Loss: 1.8934, Time: 0.17s\n",
            "Epoch 28, Loss: 1.6137, Time: 0.18s\n",
            "Epoch 29, Loss: 1.7062, Time: 0.18s\n",
            "\n",
            "[Epoch 30] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.004 seconds, peak memory: 23.006 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 23.006 GB\n",
            "Metis partitioning: 0.062 seconds, peak memory: 23.006 GB\n",
            "Epoch 30, Loss: 1.6058, Time: 0.37s\n",
            "Epoch 31, Loss: 1.6730, Time: 0.18s\n",
            "Epoch 32, Loss: 1.7259, Time: 0.18s\n",
            "Epoch 33, Loss: 1.6690, Time: 0.18s\n",
            "Epoch 34, Loss: 1.6159, Time: 0.17s\n",
            "\n",
            "[Epoch 35] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 23.006 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 23.006 GB\n",
            "Metis partitioning: 0.057 seconds, peak memory: 23.006 GB\n",
            "Epoch 35, Loss: 1.2562, Time: 0.34s\n",
            "Epoch 36, Loss: 1.2233, Time: 0.17s\n",
            "Epoch 37, Loss: 1.4058, Time: 0.19s\n",
            "Epoch 38, Loss: 1.2692, Time: 0.17s\n",
            "Epoch 39, Loss: 1.2203, Time: 0.18s\n",
            "\n",
            "[Epoch 40] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 23.006 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 23.006 GB\n",
            "Metis partitioning: 0.055 seconds, peak memory: 23.006 GB\n",
            "Epoch 40, Loss: 1.5124, Time: 0.34s\n",
            "Epoch 41, Loss: 1.1919, Time: 0.17s\n",
            "Epoch 42, Loss: 1.3430, Time: 0.18s\n",
            "Epoch 43, Loss: 1.2953, Time: 0.16s\n",
            "Epoch 44, Loss: 1.1360, Time: 0.17s\n",
            "\n",
            "[Epoch 45] Re-partitioning graph...\n",
            "Convert a graph into a bidirected graph: 0.003 seconds, peak memory: 23.006 GB\n",
            "Construct multi-constraint weights: 0.000 seconds, peak memory: 23.006 GB\n",
            "Metis partitioning: 0.055 seconds, peak memory: 23.006 GB\n",
            "Epoch 45, Loss: 1.0995, Time: 0.34s\n",
            "Epoch 46, Loss: 0.9396, Time: 0.17s\n",
            "Epoch 47, Loss: 1.1151, Time: 0.18s\n",
            "Epoch 48, Loss: 1.1413, Time: 0.17s\n",
            "Epoch 49, Loss: 0.8592, Time: 0.17s\n",
            "Test Accuracy: 0.762\n"
          ]
        }
      ]
    }
  ]
}